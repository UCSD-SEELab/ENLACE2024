# Human Activity Data Collection, Analysis and LLM-based Zero-Shot Reasoning
Hello reader! In this repository, you will find the codes necessary to decompress and save the information in a CSV file collected by a smartphone, the visualization and the statistical analysis of the data, and the Python code to call ChatGPT 3.5 turbo.

Enjoy(;

## Introduction
Our project aims to recognize human activities performed by multiple subjects for their subsequent prediction based on Zero-shot reasoning. The future goal is to obtain a system for health monitoring, aging care, and human behavior analysis.

## Method
Before processing the sensor data, the work published in "Introduction to the ExtraSensory Dataset" was taken as a reference to read the userâ€™s data file, the analysis of the context labels and the sensor features as well as their relationship. This part is in the visualizer.py code.
The process for preparing the IMU raw dataset is described below:
-	Dataset collection
-	Data analysis
-	Feature extraction on sensor dataset
-	Zero-shot reasoning and prompt input

The process for preparing the IMU raw dataset is described below:
1. Dataset collection
To begin, the data recorded in the ExtraSensory app is collected and stored on its corresponding server. Once the data are obtained, the data is unzipped, processed, and saved in a folder.

2. Data analysis
The labels users report are graphed to visualize activities over time and identify the main activities.

3. Feature extraction on sensor dataset
Sensor features were extracted


## Result


